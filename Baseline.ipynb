{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48aff5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/xgboost-python-package/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\daner\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\daner\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Location '/kaggle/input/xgboost-python-package/' is ignored: it is either a non-existing path or lacks a specific scheme.\n",
      "ERROR: Could not find a version that satisfies the requirement xgboost (from versions: none)\n",
      "ERROR: No matching distribution found for xgboost\n"
     ]
    }
   ],
   "source": [
    "!pip install -U xgboost -f /kaggle/input/xgboost-python-package/ --no-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9704697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from colorama import Fore, Style, init;\n",
    "\n",
    "# Modeling\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "\n",
    "# Options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "DEBUG = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7b8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df(df, name):\n",
    "    '''Display df shape and first row '''\n",
    "    PrintColor(text = f'{name} data has {df.shape[0]} rows and {df.shape[1]} columns. \\n ===> First row:')\n",
    "    display(df.head(1))\n",
    "\n",
    "# Color printing    \n",
    "def PrintColor(text:str, color = Fore.BLUE, style = Style.BRIGHT):\n",
    "    '''Prints color outputs using colorama of a text string'''\n",
    "    print(style + color + text + Style.RESET_ALL); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a15718b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DIR = \"predict-energy-behavior-of-prosumers/\"\n",
    "\n",
    "train = pd.read_csv(CSV_DIR + \"train.csv\")\n",
    "client = pd.read_csv(CSV_DIR + \"client.csv\")\n",
    "historical_weather = pd.read_csv(CSV_DIR + \"historical_weather.csv\")\n",
    "forecast_weather = pd.read_csv(CSV_DIR + \"forecast_weather.csv\")\n",
    "electricity = pd.read_csv(CSV_DIR + \"electricity_prices.csv\")\n",
    "gas = pd.read_csv(CSV_DIR + \"gas_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c4b79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mtrain data has 2018352 rows and 9 columns. \n",
      " ===> First row:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   county  is_business  product_type  target  is_consumption  \\\n",
       "0       0            0             1   0.713               0   \n",
       "\n",
       "              datetime  data_block_id  row_id  prediction_unit_id  \n",
       "0  2021-09-01 00:00:00              0       0                   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mclient data has 41919 rows and 7 columns. \n",
      " ===> First row:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>county</th>\n",
       "      <th>eic_count</th>\n",
       "      <th>installed_capacity</th>\n",
       "      <th>is_business</th>\n",
       "      <th>date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>952.89</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_type  county  eic_count  installed_capacity  is_business  \\\n",
       "0             1       0        108              952.89            0   \n",
       "\n",
       "         date  data_block_id  \n",
       "0  2021-09-01              2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mhistoric weather data has 1710800 rows and 18 columns. \n",
      " ===> First row:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>windspeed_10m</th>\n",
       "      <th>winddirection_10m</th>\n",
       "      <th>shortwave_radiation</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>diffuse_radiation</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>14.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.694444</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.6</td>\n",
       "      <td>21.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  temperature  dewpoint  rain  snowfall  \\\n",
       "0  2021-09-01 00:00:00         14.4      12.0   0.0       0.0   \n",
       "\n",
       "   surface_pressure  cloudcover_total  cloudcover_low  cloudcover_mid  \\\n",
       "0            1015.8                 4               4               0   \n",
       "\n",
       "   cloudcover_high  windspeed_10m  winddirection_10m  shortwave_radiation  \\\n",
       "0                0       6.694444                  3                  0.0   \n",
       "\n",
       "   direct_solar_radiation  diffuse_radiation  latitude  longitude  \\\n",
       "0                     0.0                0.0      57.6       21.7   \n",
       "\n",
       "   data_block_id  \n",
       "0              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mforecast weather data has 3424512 rows and 18 columns. \n",
      " ===> First row:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>origin_datetime</th>\n",
       "      <th>hours_ahead</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>cloudcover_high</th>\n",
       "      <th>cloudcover_low</th>\n",
       "      <th>cloudcover_mid</th>\n",
       "      <th>cloudcover_total</th>\n",
       "      <th>10_metre_u_wind_component</th>\n",
       "      <th>10_metre_v_wind_component</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>forecast_datetime</th>\n",
       "      <th>direct_solar_radiation</th>\n",
       "      <th>surface_solar_radiation_downwards</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>total_precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.6</td>\n",
       "      <td>21.7</td>\n",
       "      <td>2021-09-01 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>15.655786</td>\n",
       "      <td>11.553613</td>\n",
       "      <td>0.904816</td>\n",
       "      <td>0.019714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.905899</td>\n",
       "      <td>-0.411328</td>\n",
       "      <td>-9.106137</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01 01:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude            origin_datetime  hours_ahead  temperature  \\\n",
       "0      57.6       21.7  2021-09-01 00:00:00+00:00            1    15.655786   \n",
       "\n",
       "    dewpoint  cloudcover_high  cloudcover_low  cloudcover_mid  \\\n",
       "0  11.553613         0.904816        0.019714             0.0   \n",
       "\n",
       "   cloudcover_total  10_metre_u_wind_component  10_metre_v_wind_component  \\\n",
       "0          0.905899                  -0.411328                  -9.106137   \n",
       "\n",
       "   data_block_id          forecast_datetime  direct_solar_radiation  \\\n",
       "0              1  2021-09-01 01:00:00+00:00                     0.0   \n",
       "\n",
       "   surface_solar_radiation_downwards  snowfall  total_precipitation  \n",
       "0                                0.0       0.0                  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34melectricity prices data has 15286 rows and 4 columns. \n",
      " ===> First row:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>euros_per_mwh</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>92.51</td>\n",
       "      <td>2021-08-31 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         forecast_date  euros_per_mwh          origin_date  data_block_id\n",
       "0  2021-09-01 00:00:00          92.51  2021-08-31 00:00:00              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mgas prices data has 637 rows and 5 columns. \n",
      " ===> First row:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>lowest_price_per_mwh</th>\n",
       "      <th>highest_price_per_mwh</th>\n",
       "      <th>origin_date</th>\n",
       "      <th>data_block_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>45.23</td>\n",
       "      <td>46.32</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  forecast_date  lowest_price_per_mwh  highest_price_per_mwh origin_date  \\\n",
       "0    2021-09-01                 45.23                  46.32  2021-08-31   \n",
       "\n",
       "   data_block_id  \n",
       "0              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_df(train, 'train')\n",
    "display_df(client, 'client')\n",
    "display_df(historical_weather, 'historic weather')\n",
    "display_df(forecast_weather, 'forecast weather')\n",
    "display_df(electricity, 'electricity prices')\n",
    "display_df(gas, 'gas prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60bd30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureProcessorClass():\n",
    "    def __init__(self):         \n",
    "        # Columns to join on for the different datasets\n",
    "        self.historical_weather_join = ['datetime', 'data_block_id']\n",
    "        self.forecast_weather_join = ['datetime', 'data_block_id'] \n",
    "        self.gas_join = ['data_block_id']\n",
    "        self.electricity_join = ['datetime', 'data_block_id']\n",
    "        self.client_join = ['county', 'is_business', 'product_type', 'data_block_id']\n",
    "        \n",
    "        # Categorical columns (specify for XGBoost)\n",
    "        self.category_columns = ['county', 'is_business', 'product_type', 'is_consumption', 'data_block_id']\n",
    "\n",
    "    def create_new_column_names(self, df, suffix, columns_no_change):\n",
    "        '''Change column names by given suffix, keep columns_no_change, and return back the data'''\n",
    "        df.columns = [col + suffix \n",
    "                      if col not in columns_no_change\n",
    "                      else col\n",
    "                      for col in df.columns\n",
    "                      ]\n",
    "        return df \n",
    "    \n",
    "    def create_data_features(self, data):\n",
    "        '''üìäCreate features for main data (test or train) setüìä'''\n",
    "        # To datetime\n",
    "        data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "        \n",
    "        # Time period features\n",
    "        data['date'] = data['datetime'].dt.normalize()\n",
    "        data['year'] = data['datetime'].dt.year\n",
    "        data['quarter'] = data['datetime'].dt.quarter\n",
    "        data['month'] = data['datetime'].dt.month\n",
    "        data['week'] = data['datetime'].dt.isocalendar().week\n",
    "        data['hour'] = data['datetime'].dt.hour\n",
    "        \n",
    "        # Day features\n",
    "        data['day_of_year'] = data['datetime'].dt.day_of_year\n",
    "        data['day_of_month']  = data['datetime'].dt.day\n",
    "        data['day_of_week'] = data['datetime'].dt.day_of_week\n",
    "        return data\n",
    "\n",
    "    def create_client_features(self, client):\n",
    "        '''üíº Create client features üíº'''\n",
    "        # Modify column names - specify suffix\n",
    "        client = self.create_new_column_names(client, \n",
    "                                           suffix='_client',\n",
    "                                           columns_no_change = self.client_join\n",
    "                                          )       \n",
    "        return client\n",
    "    \n",
    "    def create_historical_weather_features(self, historical_weather):\n",
    "        '''‚åõüå§Ô∏è Create historical weather features üå§Ô∏è‚åõ'''\n",
    "        # To datetime\n",
    "        historical_weather['datetime'] = pd.to_datetime(historical_weather['datetime'])\n",
    "        \n",
    "        # Group by mean for datetime & data_block_id (note: the latitude/longitude not taken into account)\n",
    "        historical_weather_mean = historical_weather.groupby(['datetime', 'data_block_id']).mean().reset_index() \n",
    "        \n",
    "        # Test set has 1 day offset for hour<11 and 2 day offset for hour>11\n",
    "        historical_weather_mean['hour'] = historical_weather_mean['datetime'].dt.hour\n",
    "        historical_weather_mean['datetime'] = (historical_weather_mean\n",
    "                                               .apply(lambda x: \n",
    "                                                      x['datetime'] + pd.DateOffset(1) \n",
    "                                                      if x['hour']< 11 \n",
    "                                                      else x['datetime'] + pd.DateOffset(2),\n",
    "                                                      axis=1)\n",
    "                                              )\n",
    "        \n",
    "        # Modify column names - specify suffix\n",
    "        historical_weather_mean = self.create_new_column_names(historical_weather_mean,\n",
    "                                                               suffix='_historical',\n",
    "                                                               columns_no_change = self.historical_weather_join\n",
    "                                                              )                                      \n",
    "        return historical_weather_mean\n",
    "    \n",
    "    def create_forecast_weather_features(self, forecast_weather):\n",
    "        '''üîÆüå§Ô∏è Create forecast weather features üå§Ô∏èüîÆ'''\n",
    "        # Rename column\n",
    "        forecast_weather = forecast_weather.rename(columns = {'forecast_datetime': 'datetime'})   \n",
    "        \n",
    "        # To datetime\n",
    "        forecast_weather['origin_datetime'] = pd.to_datetime(forecast_weather['origin_datetime']).dt.tz_localize(None)\n",
    "        forecast_weather['datetime'] = pd.to_datetime(forecast_weather['datetime']).dt.tz_localize(None)\n",
    "\n",
    "        # Groupby mean for origin_datetime & hours_ahead & data_block_id (note: the latitude/longitude not taken into account)\n",
    "        forecast_weather_mean = forecast_weather.groupby(['origin_datetime', 'hours_ahead', 'data_block_id']).mean().reset_index() \n",
    "        \n",
    "        # Modify column names - specify suffix\n",
    "        forecast_weather_mean = self.create_new_column_names(forecast_weather_mean, \n",
    "                                                             suffix='_forecast',\n",
    "                                                             columns_no_change = self.forecast_weather_join\n",
    "                                                            )                                     \n",
    "        return forecast_weather_mean\n",
    "\n",
    "    def create_electricity_features(self, electricity):\n",
    "        '''‚ö° Create electricity prices features ‚ö°'''\n",
    "        # To datetime\n",
    "        electricity['forecast_date'] = pd.to_datetime(electricity['forecast_date'])\n",
    "        \n",
    "        # Test set has 1 day offset\n",
    "        electricity['datetime'] = electricity['forecast_date'] + pd.DateOffset(1)\n",
    "        \n",
    "        # Modify column names - specify suffix\n",
    "        electricity = self.create_new_column_names(electricity, \n",
    "                                                   suffix='_electricity',\n",
    "                                                   columns_no_change = self.electricity_join\n",
    "                                                  )             \n",
    "        return electricity\n",
    "\n",
    "    def create_gas_features(self, gas):\n",
    "        '''‚õΩ Create gas prices features ‚õΩ'''\n",
    "        # Mean gas price\n",
    "        gas['mean_price_per_mwh'] = (gas['lowest_price_per_mwh'] + gas['highest_price_per_mwh'])/2\n",
    "        \n",
    "        # Modify column names - specify suffix\n",
    "        gas = self.create_new_column_names(gas, \n",
    "                                           suffix='_gas',\n",
    "                                           columns_no_change = self.gas_join\n",
    "                                          )       \n",
    "        return gas\n",
    "    \n",
    "    def __call__(self, data, client, historical_weather, forecast_weather, electricity, gas):\n",
    "        '''Processing of features from all datasets, merge together and return features for dataframe df '''\n",
    "        # Create features for relevant dataset\n",
    "        data = self.create_data_features(data)\n",
    "        client = self.create_client_features(client)\n",
    "        historical_weather = self.create_historical_weather_features(historical_weather)\n",
    "        forecast_weather = self.create_forecast_weather_features(forecast_weather)\n",
    "        electricity = self.create_electricity_features(electricity)\n",
    "        gas = self.create_gas_features(gas)\n",
    "        \n",
    "        # üîó Merge all datasets into one df üîó\n",
    "        df = data.merge(client, how='left', on = self.client_join)\n",
    "        df = df.merge(historical_weather, how='left', on = self.historical_weather_join)\n",
    "        df = df.merge(forecast_weather, how='left', on = self.forecast_weather_join)\n",
    "        df = df.merge(electricity, how='left', on = self.electricity_join)\n",
    "        df = df.merge(gas, how='left', on = self.gas_join)\n",
    "        \n",
    "        # Change columns to categorical for XGBoost\n",
    "        df[self.category_columns] = df[self.category_columns].astype('category')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fc98558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_revealed_targets_train(data, N_day_shifts):\n",
    "    '''üéØ Create new train data based on N_day_shifts üéØ '''    \n",
    "    original_datetime = data['datetime']\n",
    "    revealed_targets = data[['datetime', 'prediction_unit_id', 'is_consumption', 'target']].copy()\n",
    "    \n",
    "    # Create revealed targets for all day shifts\n",
    "    for day_shift in range(2, N_day_shifts+1):\n",
    "        revealed_targets['datetime'] = original_datetime + pd.DateOffset(day_shift)\n",
    "        data = data.merge(revealed_targets, \n",
    "                          how='left', \n",
    "                          on = ['datetime', 'prediction_unit_id', 'is_consumption'],\n",
    "                          suffixes = ('', f'_{day_shift}_days_ago')\n",
    "                         )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed8aa0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daner\\AppData\\Local\\Temp\\ipykernel_11472\\1520947171.py:85: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  forecast_weather_mean = forecast_weather.groupby(['origin_datetime', 'hours_ahead', 'data_block_id']).mean().reset_index()\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:6\u001b[0m\n",
      "Cell \u001b[1;32mIn[7], line 134\u001b[0m, in \u001b[0;36mFeatureProcessorClass.__call__\u001b[1;34m(self, data, client, historical_weather, forecast_weather, electricity, gas)\u001b[0m\n\u001b[0;32m    132\u001b[0m df \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mmerge(client, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_join)\n\u001b[0;32m    133\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmerge(historical_weather, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistorical_weather_join)\n\u001b[1;32m--> 134\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecast_weather\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast_weather_join\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmerge(electricity, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melectricity_join)\n\u001b[0;32m    136\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmerge(gas, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgas_join)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:10093\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10074\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m  10075\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m  10076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10089\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10090\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m  10091\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m> 10093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10094\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10095\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10096\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10098\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10099\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10102\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10103\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[0;32m    698\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[0;32m    699\u001b[0m (\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[1;32m--> 703\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1162\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1160\u001b[0m rk \u001b[38;5;241m=\u001b[39m cast(Hashable, rk)\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1162\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     values \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\n\u001b[0;32m   1846\u001b[0m         \u001b[38;5;241m.\u001b[39mget_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m         \u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1848\u001b[0m     )\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1852\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'datetime'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create all features\n",
    "N_day_shifts = 10 # Specify how many days we want to go back (at least 2)\n",
    "\n",
    "FeatureProcessor = FeatureProcessorClass()\n",
    "\n",
    "data = FeatureProcessor(data = train.copy(),\n",
    "                      client = client.copy(),\n",
    "                      historical_weather = historical_weather.copy(),\n",
    "                      forecast_weather = forecast_weather.copy(),\n",
    "                      electricity = electricity.copy(),\n",
    "                      gas = gas.copy(),\n",
    "                     )\n",
    "\n",
    "df = create_revealed_targets_train(data.copy(), \n",
    "                                  N_day_shifts = N_day_shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc88d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
